{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alpha.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNahiX4Rl1ImEhx4q9nVIWA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amir-D-Shadow/Google-Colab/blob/main/alpha.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvlBvKdFJzrW"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "import numpy  as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuJ32tf7PY7l",
        "outputId": "095890c0-8b11-4ddc-fd82-82c17200a4b9"
      },
      "source": [
        "x = tf.constant(value = np.random.randn(10,38,38,85))\n",
        "y = K.sum(x)\n",
        "K.eval(y)\n",
        "type(K.eval(K.shape(x)[0]).item())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OToDt5qjtLzN"
      },
      "source": [
        "class alpha_loss(tf.keras.losses.Loss):\n",
        "\n",
        "  def __init__(self,gamma = 2):\n",
        "\n",
        "    super(alpha_loss,self).__init__()\n",
        "\n",
        "    self.gamma = gamma\n",
        "\n",
        "  def call(self,y_true,y_pred):\n",
        "\n",
        "    #get prob\n",
        "    prob_true = y_true[:,:,:,0]\n",
        "    prob_pred = y_pred[:,:,:,0]\n",
        "\n",
        "    #get class\n",
        "    class_true = y_true[:,:,:,5:]\n",
        "    class_pred = y_pred[:,:,:,5:]\n",
        "\n",
        "    #****************** Focal loss ******************\n",
        "\n",
        "    #get batch size\n",
        "    m = K.cast(K.shape(y_pred)[0],K.dtype(y_pred))\n",
        "\n",
        "    #clip the prediction\n",
        "    prob_pred = K.clip(prob_pred,min_value = 0.0, max_value = 1.0)\n",
        "    class_pred = K.clip(class_pred,min_value = 0.0, max_value = 1.0)\n",
        "\n",
        "    #prob focal loss\n",
        "    loss_tensor =  - ( (1 - prob_pred)**self.gamma ) * prob_true * tf.math.log( prob_pred + 1e-18 ) - ( prob_pred ** self.gamma ) * ( 1 - prob_true ) * tf.math.log( 1 - prob_pred + 1e-18 )\n",
        "    prob_focal_loss = K.sum(loss_tensor)/ m\n",
        "\n",
        "    #class focal loss\n",
        "    loss_tensor =  - ( (1 - class_pred)**self.gamma ) * class_true * tf.math.log( class_pred + 1e-18 ) - ( class_pred ** self.gamma) * ( 1 - class_true ) * tf.math.log( 1 - class_pred + 1e-18 )\n",
        "    class_focal_loss = K.sum(loss_tensor) / m\n",
        "\n",
        "\n",
        "    #****************** Focal loss ******************\n",
        "\n",
        "    #get reg left -- (x,y)\n",
        "    reg_left_true = y_true[:,:,:,1:3] \n",
        "    reg_left_pred = y_pred[:,:,:,1:3]\n",
        "\n",
        "    #get reg center -- (x,y)\n",
        "    reg_center_true = y_true[:,:,:,3:5] \n",
        "    reg_center_pred = y_pred[:,:,:,3:5]\n",
        "\n",
        "    #calculate width\n",
        "    reg_width_true = (reg_center_true[:,:,:,0] - reg_left_true[:,:,:,0])*2\n",
        "    reg_width_pred = (reg_center_pred[:,:,:,0] - reg_left_pred[:,:,:,0])*2 \n",
        "\n",
        "    #calculate height\n",
        "    reg_height_true = (reg_center_true[:,:,:,1] - reg_left_true[:,:,:,1])*2\n",
        "    reg_height_pred = (reg_center_pred[:,:,:,1] - reg_left_pred[:,:,:,1])*2\n",
        "\n",
        "    #calculate reg right\n",
        "\n",
        "    #calculate loss\n",
        "    loss = prob_focal_loss + class_focal_loss\n",
        "\n",
        "    return loss"
      ],
      "execution_count": 303,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_773ppAXetX",
        "outputId": "477ec049-6d52-4a86-d29a-e2d6f6fd1223"
      },
      "source": [
        "y_true = tf.constant(value = np.random.randint(0,2,size=(10,36,36,85)),dtype=np.float64)\n",
        "data = tf.constant(value= np.random.randn(10,38,38,128),dtype=np.float64)\n",
        "\n",
        "x = tf.keras.layers.Input(shape =(38,38,128))\n",
        "\n",
        "k1 = tf.keras.layers.BatchNormalization(axis=-1)(x)\n",
        "h1 = tf.keras.layers.Conv2D(128,3,1,\"valid\",data_format=\"channels_last\")(k1)\n",
        "h2 = tf.keras.layers.BatchNormalization(axis=-1)(h1)\n",
        "h3 = tf.keras.layers.LeakyReLU()(h2)\n",
        "h4 = tf.keras.layers.Conv2D(85,3,1,\"same\",data_format=\"channels_last\")(h3)\n",
        "h5 = tf.keras.layers.BatchNormalization(axis=-1)(h4)\n",
        "h6 = tf.keras.layers.LeakyReLU()(h5)\n",
        "k2 = tf.keras.layers.Conv2D(85,3,1,\"same\",data_format=\"channels_last\",activation=\"swish\")(h6)\n",
        "\n",
        "model = tf.keras.Model(inputs=x,outputs=k2)\n",
        "\n",
        "model.compile(optimizer=\"adam\",loss=alpha_loss())\n",
        "\n",
        "b = model.fit(data,y_true,epochs=50)\n"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1172799.0000\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 1s 676ms/step - loss: 1040104.1250\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 947829.1875\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 888043.3750\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 1s 648ms/step - loss: 850676.8750\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 1s 660ms/step - loss: 829665.8125\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 818031.1875\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 1s 648ms/step - loss: 813657.3750\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 812853.3750\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 1s 661ms/step - loss: 813859.6875\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 814512.8750\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 813258.0000\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 1s 662ms/step - loss: 811493.1250\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 808022.1250\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 1s 681ms/step - loss: 803690.0000\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 1s 684ms/step - loss: 799038.8750\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 1s 656ms/step - loss: 793476.2500\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 788129.3125\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 782007.6875\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 776403.0625\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 771054.8125\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 1s 666ms/step - loss: 765997.8125\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 1s 672ms/step - loss: 761072.3750\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 1s 669ms/step - loss: 756552.3125\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 751844.8750\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 747054.7500\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 743237.1250\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 1s 657ms/step - loss: 739901.3125\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 736758.7500\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 1s 665ms/step - loss: 734615.6875\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 1s 652ms/step - loss: 732164.0625\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 1s 694ms/step - loss: 729360.1875\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 1s 679ms/step - loss: 727406.1250\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 725450.6250\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 722992.6250\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 1s 673ms/step - loss: 720522.1250\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 1s 659ms/step - loss: 718289.8750\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 1s 670ms/step - loss: 716451.3125\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 1s 668ms/step - loss: 714453.1250\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 1s 644ms/step - loss: 712636.1250\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 1s 667ms/step - loss: 710704.6250\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 708902.3750\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 707596.8750\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 706127.6250\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 1s 663ms/step - loss: 704504.2500\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 1s 653ms/step - loss: 702880.6875\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 1s 671ms/step - loss: 700835.5000\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 1s 658ms/step - loss: 698990.6250\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 1s 655ms/step - loss: 696915.0000\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 1s 651ms/step - loss: 694505.5625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWEQaL2XgFTD",
        "outputId": "a5ef54e2-ecbd-410f-ecfd-b019658ff8b0"
      },
      "source": [
        "tf.nn.swish(-5.0)"
      ],
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=-0.03346458>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    }
  ]
}